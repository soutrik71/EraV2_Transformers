{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers all the optimization steps for training an encoder-decoder transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/insights-model-run2/code/Users/soutrik.chowdhury/EraV2_Transformers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\n",
    "    \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/insights-model-run2/code/Users/soutrik.chowdhury/EraV2_Transformers\"\n",
    ")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from S18_code.config import get_config, get_weights_file_path\n",
    "from S18_code.model import build_transformer\n",
    "import torch\n",
    "from S18_code.dataloader import get_ds\n",
    "from datasets import load_dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "from torch.optim import Adam\n",
    "from torchmetrics.text import BLEUScore\n",
    "from torch.cuda.amp import GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = get_config()[\"device\"]\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "Tesla V100-PCIE-16GB\n",
      "0\n",
      "0\n",
      "Tesla V100-PCIE-16GB\n",
      "15.7725830078125\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n",
      "(7, 0)\n",
      "_CudaDeviceProperties(name='Tesla V100-PCIE-16GB', major=7, minor=0, total_memory=16151MB, multi_processor_count=80)\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.memory_allocated())\n",
    "print(torch.cuda.memory_reserved())\n",
    "print(torch.cuda.get_device_name(device.index))\n",
    "print(torch.cuda.get_device_properties(device.index).total_memory / 1024**3)\n",
    "print(torch.cuda.memory_summary(device=device.index))\n",
    "print(torch.cuda.get_device_capability(device.index))\n",
    "print(torch.cuda.get_device_properties(device.index))\n",
    "print(torch.cuda.get_device_properties(device.index).multi_processor_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dataset and create data via dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32332\n"
     ]
    }
   ],
   "source": [
    "ds_raw = load_dataset(\n",
    "    get_config()[\"datasource\"],\n",
    "    f\"{get_config()['src_lang']}-{get_config()['tgt_lang']}\",\n",
    "    split=\"train\",\n",
    ")\n",
    "print(len(ds_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tokenizer for en\n",
      "Tokenizer for en already exists\n",
      "Building tokenizer for it\n",
      "Tokenizer for it already exists\n",
      "Creating the tokenized-dataset\n",
      "Dataloaders created with 29098 training and 3234 validation samples\n"
     ]
    }
   ],
   "source": [
    "# batch wise padding data loading\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(\n",
    "    ds_raw, get_config()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/torch_env/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 70])\n",
      "torch.Size([16, 44])\n",
      "torch.Size([16, 1, 1, 70])\n",
      "torch.Size([16, 1, 44, 44])\n"
     ]
    }
   ],
   "source": [
    "for data in train_dataloader:\n",
    "    print(data[\"encoder_input\"].shape)\n",
    "    print(data[\"decoder_input\"].shape)\n",
    "    print(data[\"encoder_mask\"].shape)\n",
    "    print(data[\"decoder_mask\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28])\n",
      "torch.Size([1, 27])\n",
      "torch.Size([1, 1, 1, 28])\n",
      "torch.Size([1, 1, 27, 27])\n"
     ]
    }
   ],
   "source": [
    "for data in val_dataloader:\n",
    "    print(data[\"encoder_input\"].shape)\n",
    "    print(data[\"decoder_input\"].shape)\n",
    "    print(data[\"encoder_mask\"].shape)\n",
    "    print(data[\"decoder_mask\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Initialization and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = build_transformer(\n",
    "    src_vocab_size=tokenizer_src.get_vocab_size(),\n",
    "    tgt_vocab_size=tokenizer_tgt.get_vocab_size(),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "TransformerModel                                        --\n",
       "├─Encoder: 1-1                                          --\n",
       "│    └─ModuleList: 2-1                                  --\n",
       "│    │    └─EncoderBlock: 3-1                           3,150,336\n",
       "│    │    └─EncoderBlock: 3-2                           3,150,336\n",
       "│    │    └─EncoderBlock: 3-3                           3,150,336\n",
       "│    │    └─EncoderBlock: 3-4                           3,150,336\n",
       "│    │    └─EncoderBlock: 3-5                           3,150,336\n",
       "│    │    └─EncoderBlock: 3-6                           3,150,336\n",
       "│    └─LayerNormalization: 2-2                          1,024\n",
       "├─Decoder: 1-2                                          --\n",
       "│    └─ModuleList: 2-3                                  --\n",
       "│    │    └─DecoderBlock: 3-7                           4,199,936\n",
       "│    │    └─DecoderBlock: 3-8                           4,199,936\n",
       "│    │    └─DecoderBlock: 3-9                           4,199,936\n",
       "│    │    └─DecoderBlock: 3-10                          4,199,936\n",
       "│    │    └─DecoderBlock: 3-11                          4,199,936\n",
       "│    │    └─DecoderBlock: 3-12                          4,199,936\n",
       "│    └─LayerNormalization: 2-4                          1,024\n",
       "├─InputEmbeddings: 1-3                                  --\n",
       "│    └─Embedding: 2-5                                   7,451,648\n",
       "├─InputEmbeddings: 1-4                                  --\n",
       "│    └─Embedding: 2-6                                   10,957,312\n",
       "├─PositionalEncoding: 1-5                               --\n",
       "│    └─Dropout: 2-7                                     --\n",
       "├─PositionalEncoding: 1-6                               --\n",
       "│    └─Dropout: 2-8                                     --\n",
       "├─ProjectionLayer: 1-7                                  --\n",
       "│    └─Linear: 2-9                                      10,978,713\n",
       "================================================================================\n",
       "Total params: 73,491,353\n",
       "Trainable params: 73,491,353\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will do basic training and validation based on:\n",
    "* Application of basic training loop\n",
    "* Application of custom scheduler for learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from S18_code.trainer import (\n",
    "    CustomLRScheduler,\n",
    "    TranslationLoss,\n",
    "    run_training_loop_basic,\n",
    "    run_validation_loop,\n",
    "    greedy_decode,\n",
    "    run_inference_loop,\n",
    "    run_training_loop_opt,\n",
    "    run_training_loop_opt_clip,\n",
    ")\n",
    "\n",
    "from S18_code.utils import start_timer, end_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = tokenizer_src.token_to_id(\"[PAD]\")\n",
    "sos_idx = tokenizer_src.token_to_id(\"[SOS]\")\n",
    "eos_idx = tokenizer_src.token_to_id(\"[EOS]\")\n",
    "label_smoothing = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/torch_env/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "# Optimizer Adam with weight decay\n",
    "optimizer = Adam(\n",
    "    transformer_model.parameters(),\n",
    "    betas=(0.9, 0.98),\n",
    "    eps=1.0e-9,\n",
    "    lr=get_config()[\"learning_rate\"],\n",
    ")\n",
    "# Learning rate scheduler\n",
    "scheduler = CustomLRScheduler(optimizer, get_config()[\"d_model\"], 1000)\n",
    "# Loss function\n",
    "criterion = TranslationLoss(pad_idx, label_smoothing, tokenizer_tgt)\n",
    "# BLEU score metric\n",
    "metric = BLEUScore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(get_config()[\"num_epochs\"]):\n",
    "#     global_step = 0\n",
    "#     train_loss, global_step = run_training_loop_basic(\n",
    "#         transformer_model,\n",
    "#         train_dataloader,\n",
    "#         optimizer,\n",
    "#         criterion,\n",
    "#         device,\n",
    "#         global_step,\n",
    "#         scheduler,\n",
    "#     )\n",
    "#     print(f\"Epoch: {epoch}, Train loss: {train_loss}\")\n",
    "\n",
    "#     val_loss = run_validation_loop(transformer_model, val_dataloader, criterion, device)\n",
    "#     print(f\"Epoch: {epoch}, Validation loss: {val_loss}\")\n",
    "\n",
    "#     run_inference_loop(\n",
    "#         transformer_model,\n",
    "#         val_dataloader,\n",
    "#         tokenizer_tgt,\n",
    "#         device,\n",
    "#         5,\n",
    "#         metric,\n",
    "#         sos_idx,\n",
    "#         eos_idx,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application of optimization techniques on training loop to improve performance:\n",
    "* Automatic Mixed Precision\n",
    "* Gradient Scaling (Gradient Clipping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/torch_env/lib/python3.10/site-packages/torch/cuda/memory.py:330: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory used in start: 0.28GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | 0/1819 [00:00<?, ?it/s]/anaconda/envs/torch_env/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1819/1819 [04:27<00:00,  7.09it/s, loss=5.827]/anaconda/envs/torch_env/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1819/1819 [04:27<00:00,  6.80it/s, loss=5.827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 6.395487659248826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3234/3234 [01:32<00:00, 35.05it/s, loss=6.284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Validation loss: 5.706320371757559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 1/3234 [00:00<09:04,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: There are great moors behind and on each hand of me; there are waves of mountains far beyond that deep valley at my feet.\n",
      "TARGET: Gruppi di paduli si estendevano da ogni lato, e al di là della profonda vallata che aveva ai piedi sorgeva una catena di colline.\n",
      "PREDICTED: e non è un ' altra .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|▉                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 3/3234 [00:01<19:25,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: After the game Vronsky and Levin joined Gagin at his table, and at Oblonsky's invitation Levin began betting on aces.\n",
      "TARGET: Dopo la partita, Vronskij e Levin sedettero vicino al tavolo di Gagin, e Levin, su proposta di Stepan Arkad’ic, si mise a puntare sugli assi.\n",
      "PREDICTED: levin , e il fratello , e il fratello , e il figlio , e il figlio , e il figlio , e il figlio , e il suo sguardo di lei , e il suo sguardo , e il suo sguardo di lei .\n",
      "SOURCE: Hannah says you have had nothing but some gruel since breakfast.\"\n",
      "TARGET: Anna mi ha detto che dopo colazione avevate mangiato soltanto un poco di farinata.\n",
      "PREDICTED: — non è un ' è un ' altra .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|█▏                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 4/3234 [00:02<42:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: Levin had been five days in Kashin, going daily to meetings and taking a great deal of trouble over his sister's business, which he was still unable to arrange.\n",
      "TARGET: Levin era a Kašin già da sei giorni, frequentando tutti i giorni l’assemblea e affannandosi per l’affare della sorella che non riusciva a sistemare.\n",
      "PREDICTED: levin , e il suo sguardo , e il suo sguardo di lei , e il suo sguardo di lei , e il suo sguardo di lei , e il suo sguardo , e il suo sguardo di lei , e il suo sguardo di lei , e il suo sguardo di lei , e il suo sguardo di lei , e il suo sguardo di lei , e il suo sguardo di lei , e il suo sguardo di lei , e il suo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|█▍                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 5/3234 [00:04<47:30,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: Fancies, memories, and most strange thoughts followed one another with extreme rapidity and clearness: now he saw himself pouring out medicine for the patient and overfilling the spoon, then he saw the midwife's white hands, or Karenin's curious pose as he knelt on the floor by her bedside.\n",
      "TARGET: Le immagini, le memorie e le idee più strane si susseguivano le une alle altre con straordinaria velocità e chiarezza: ora la medicina che aveva versato all’ammalata e che aveva fatto gocciolare dal cucchiaino, ora le braccia bianche della levatrice, o la strana posizione di Aleksej Aleksandrovic sul pavimento, davanti al letto.\n",
      "PREDICTED: il suo sguardo di nuovo , e il suo padre , e il suo , e il suo sguardo , e il suo sguardo , e il suo , e il suo , e il suo , e il suo sguardo , e il suo padre , e il suo sguardo , e il suo sguardo , e il suo sguardo , e il suo sguardo , e il suo sguardo , e il suo sguardo , e il suo sguardo , e il suo sguardo , e il suo sguardo , e il suo sguardo , e il suo sguardo , e il suo sguardo , e il\n",
      "BLEU Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1819/1819 [04:29<00:00,  6.75it/s, loss=5.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.8745161780556066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3234/3234 [01:30<00:00, 35.55it/s, loss=6.260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Validation loss: 5.538365214565468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 1/3234 [00:00<13:36,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: There are great moors behind and on each hand of me; there are waves of mountains far beyond that deep valley at my feet.\n",
      "TARGET: Gruppi di paduli si estendevano da ogni lato, e al di là della profonda vallata che aveva ai piedi sorgeva una catena di colline.\n",
      "PREDICTED: e mi parve che non mi , e non mi .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|▉                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 3/3234 [00:00<12:32,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: After the game Vronsky and Levin joined Gagin at his table, and at Oblonsky's invitation Levin began betting on aces.\n",
      "TARGET: Dopo la partita, Vronskij e Levin sedettero vicino al tavolo di Gagin, e Levin, su proposta di Stepan Arkad’ic, si mise a puntare sugli assi.\n",
      "PREDICTED: levin , ma non voleva dire , ma non solo nulla di lei , ma non aveva fatto nulla .\n",
      "SOURCE: Hannah says you have had nothing but some gruel since breakfast.\"\n",
      "TARGET: Anna mi ha detto che dopo colazione avevate mangiato soltanto un poco di farinata.\n",
      "PREDICTED: e che cosa non è nulla .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|█▏                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 4/3234 [00:02<39:46,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: Levin had been five days in Kashin, going daily to meetings and taking a great deal of trouble over his sister's business, which he was still unable to arrange.\n",
      "TARGET: Levin era a Kašin già da sei giorni, frequentando tutti i giorni l’assemblea e affannandosi per l’affare della sorella che non riusciva a sistemare.\n",
      "PREDICTED: ma non voleva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire , ma non poteva dire , ma non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|█▍                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 5/3234 [00:04<45:19,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE: Fancies, memories, and most strange thoughts followed one another with extreme rapidity and clearness: now he saw himself pouring out medicine for the patient and overfilling the spoon, then he saw the midwife's white hands, or Karenin's curious pose as he knelt on the floor by her bedside.\n",
      "TARGET: Le immagini, le memorie e le idee più strane si susseguivano le une alle altre con straordinaria velocità e chiarezza: ora la medicina che aveva versato all’ammalata e che aveva fatto gocciolare dal cucchiaino, ora le braccia bianche della levatrice, o la strana posizione di Aleksej Aleksandrovic sul pavimento, davanti al letto.\n",
      "PREDICTED: ma non voleva dire che non poteva dire che , ma non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire , ma non poteva dire , ma non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che non poteva dire che\n",
      "BLEU Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                                                                                                         | 1272/1819 [03:09<01:19,  6.91it/s, loss=5.810]"
     ]
    }
   ],
   "source": [
    "start_timer()\n",
    "\n",
    "for epoch in range(get_config()[\"num_epochs\"]):\n",
    "    global_step = 0\n",
    "    train_loss, global_step = run_training_loop_opt_clip(\n",
    "        transformer_model,\n",
    "        train_dataloader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        device,\n",
    "        global_step,\n",
    "        scaler,\n",
    "        scheduler,\n",
    "    )\n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss}\")\n",
    "\n",
    "    val_loss = run_validation_loop(transformer_model, val_dataloader, criterion, device)\n",
    "    print(f\"Epoch: {epoch}, Validation loss: {val_loss}\")\n",
    "\n",
    "    run_inference_loop(\n",
    "        transformer_model,\n",
    "        val_dataloader,\n",
    "        tokenizer_tgt,\n",
    "        device,\n",
    "        5,\n",
    "        metric,\n",
    "        sos_idx,\n",
    "        eos_idx,\n",
    "    )\n",
    "\n",
    "end_timer(\"Simple Neural Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_timer()\n",
    "\n",
    "# for epoch in range(get_config()[\"num_epochs\"]):\n",
    "#     global_step = 0\n",
    "#     train_loss, global_step = run_training_loop_opt_clip(\n",
    "#         transformer_model,\n",
    "#         train_dataloader,\n",
    "#         optimizer,\n",
    "#         criterion,\n",
    "#         device,\n",
    "#         global_step,\n",
    "#         scaler,\n",
    "#         scheduler,\n",
    "#     )\n",
    "#     print(f\"Epoch: {epoch}, Train loss: {train_loss}\")\n",
    "\n",
    "#     val_loss = run_validation_loop(transformer_model, val_dataloader, criterion, device)\n",
    "#     print(f\"Epoch: {epoch}, Validation loss: {val_loss}\")\n",
    "\n",
    "#     run_inference_loop(\n",
    "#         transformer_model,\n",
    "#         val_dataloader,\n",
    "#         tokenizer_tgt,\n",
    "#         device,\n",
    "#         5,\n",
    "#         metric,\n",
    "#         sos_idx,\n",
    "#         eos_idx,\n",
    "#     )\n",
    "\n",
    "# end_timer(\"Simple Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the slow update of the model is due to LR scheduler. The LR scheduler is not updating the LR as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
